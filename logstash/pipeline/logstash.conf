input {
    tcp {
        port => 5000
    }
    beats {
        port => 5044
    }
}

filter {

    if [type] == "vmware_esxi_log" {
        grok {
           match => [
              "message",
              "%{TIMESTAMP_ISO8601:log_date}%{GREEDYDATA:log_message}"
           ]
        }
        date {
            # ex: 2017-06-02T20:30:18.783Z
            match => ["log_date","ISO8601"]
            # timezone => "America/New_York"
            remove_field => ["log_date"]
        }
    }

    if [type] == "cognos_cbs_log" {
        mutate {
            gsub => ["message", "[\u0000]", ""]
        }
        grok {
            match => [
                "message",
                "\A%{HTTPDERROR_DATE:log_date}%{SPACE}%{LOGLEVEL:log_level}%{SPACE}%{SYSLOG5424PRINTASCII:event_id}%{SPACE}%{WORD:component_name}%{GREEDYDATA:log_message_raw}"
            ]
        }
        if "_grokparsefailure" in [tags] {
          drop { }
        }
        mutate {
            add_field => {
                "log_message" => "%{component_name} %{log_message_raw}"
            }
        }
        date {
            # ex: Mon May 29 14:56:51 2017
            match => ["log_date","EEE MMM dd HH:mm:ss YYYY"]
            timezone => "America/New_York"
            remove_field => ["log_date"]
        }
    }

    if [type] == "cognos_ffdc_log" {

        # Only 1 event per log file, so if we get events not starting with datestamp
        #   then it's actually part of the previous event, and better to drop than confuse.
        if [message] !~ /^------.*/ {
            drop { }
        }
        mutate {
            gsub => ["message", "[\u0000]", ""]
            add_field => {
                "tmp_message" => "%{message}"
            }
        }

        # Date
        mutate {
            gsub => ["tmp_message", "------Start of DE processing------ = \[", ""]
        }
        grok {
            match => ["tmp_message", "(?<log_date>^.*\])"]
        }
        mutate {
            gsub => ["log_date", " EDT\]", ""]
            remove_field => [ "tmp_message" ]
        }
        date {
            # ex: 5/29/17 5:59:46:564 EDT
            match => ["log_date","M/dd/YY H:mm:ss:SSS"]
            timezone => "America/New_York"
            remove_field => ["log_date"]
        }

        # Others
        mutate {
            add_field => {
                "tmp_message2" => "%{message}"
            }
        }
        mutate {
            gsub => ["tmp_message2", "\n", " newline "]
        }
        grok {
            match => [
                "tmp_message2",
                "(?<log_date>^.*??(newline))(?<exception>.*??(newline))(?<exception_source>.*??(newline))(?<probeid>.*??(newline))(?<dump>.*??(\:))"
            ]
            remove_field => ["log_date", "dump", "tmp_message2"]
        }
        mutate {
            gsub => ["exception", " Exception = ", ""]
            gsub => ["exception", " newline", ""]
            gsub => ["exception_source", " Source = ", ""]
            gsub => ["exception_source", " newline", ""]
            gsub => ["probeid", " probeid = ", ""]
            gsub => ["probeid", " newline", ""]
        }
    }

    if [type] == "cognos_ipf_log" {
        # Format is:
        #   Host ID
        #   Process ID
        #   Time
        #   Time Zone (-H)
        #   Session ID
        #   Request ID
        #   SubRequest ID
        #   Step ID
        #   Thread
        #   Component
        #   Build Number
        #   Log Level
        #   Logger
        #   Operation
        #   Object Type
        #   Object Path
        #   Status
        #   Message
        #   Log Data
        grok {
            match => {
                "message" => [
                    "\A%{URIHOST:host_id}(?<empty_tab1>\t{1})%{INT:process_id}(?<empty_tab2>\t{1})%{TIMESTAMP_ISO8601:log_date}(?<empty_tab3>\t{1})%{INT:timezone_int}(?<empty_tab4>\t{1})(?<session_id>(.*?)\t)?(?<request_id>(.*?)\t)?(?<subrequest_id>(.*?)\t)?(?<step_id>(.*?)\t)?(?<thread>(.*?)\t)(?<component>(.*?)\t)%{INT:build_number}(?<empty_tab5>\t{1})%{INT:log_level}(?<empty_tab6>\t{1})%{NOTSPACE:logger}(?<empty_tab12>\t{1})(%{WORD:operation})?(?<empty_tab7>\t{1})((?<object_type>(.*?)\t))?((?<object_path>(.*?)\t))?(%{NOTSPACE:status})?(?<empty_tab8>\t{1})?((?<log_message>(.*?)\t))?(?<log_data>(.*?)$)",
                    "\A%{URIHOST:host_id}(?<empty_tab1>\t{1})%{INT:process_id}(?<empty_tab2>\t{1})%{TIMESTAMP_ISO8601:log_date}(?<empty_tab3>\t{1})%{INT:timezone_int}(?<empty_tab4>\t{1})(%{WORD:session_id})?(?<empty_tab5>\t{1})(%{WORD:request_id})?(?<empty_tab6>\t{1})(%{WORD:subrequest_id})?(?<empty_tab7>\t{1})(%{WORD:step_id})?(?<empty_tab8>\t{1})(?<thread>(.*?)\t)%{WORD:component}(?<empty_tab9>\t{1})%{INT:build_number}(?<empty_tab10>\t{1})%{INT:log_level}(?<empty_tab11>\t{1})%{NOTSPACE:logger}(?<empty_tab12>\t{1})(%{WORD:operation})?(?<log_message>(.*?)\t)"
                ]
            }
        }
        mutate {
            gsub => ["session_id", "\t", ""]
            gsub => ["request_id", "\t", ""]
            gsub => ["subrequest_id", "\t", ""]
            gsub => ["step_id", "\t", ""]
            gsub => ["component", "\t", ""]
            gsub => ["thread", "\t", ""]
            gsub => ["object_type", "\t", ""]
            gsub => ["object_path", "\t", ""]
            gsub => ["log_message", "\t", ""]
            remove_field => [
                "empty_tab1",
                "empty_tab2",
                "empty_tab3",
                "empty_tab4",
                "empty_tab5",
                "empty_tab6",
                "empty_tab7",
                "empty_tab8",
                "empty_tab9",
                "empty_tab10",
                "empty_tab11",
                "empty_tab12"
            ]
        }
        date {
            # ex: 2017-05-29 13:15:15.814
            match => ["log_date","YYYY-MM-dd HH:mm:ss.SSS"]
            timezone => "America/New_York"
            remove_field => ["log_date"]
        }
    }

    if [type] == "cognos_p2pd_log" or [type] == "cognos_wlp_log" {
        # Initial log message
        if ([message] =~ "\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*") {
            drop { }
        }

        grok {
            match => [
                "message",
                "\A(?<log_date>^.*??(\]))%{SPACE}%{NOTSPACE:event_id}%{SPACE}%{GREEDYDATA:unparsed_log_message}"
            ]
        }
        mutate {
            gsub => ["log_date", "\[", ""]
            gsub => ["log_date", "\]", ""]
            gsub => ["log_date", " EDT", ""]
            gsub => ["event_code", "\:", ""]
        }

        # Additional log message fields if available.
        grok {
            match => {
                "unparsed_log_message" => [
                    "\A(?<namespace>^((\.){0,1}[a-zA-Z0-9\-])+((\.){1}[a-zA-Z0-9\-]+){1})%{SPACE}(?<log_level_char>[A-Z]{1})(?<empty_space1>[\s]{1})(?<event_service>[A-Za-z]{1,20}[0-9]{0,5}[A-Za-z]{0,5}\:\s)?%{GREEDYDATA:log_message}",
                    "\A(?<ex_log_level_word>^[a-zA-Z0-9]+)%{SPACE}(?<log_level_char>[A-Z]{1})(?<empty_space1>[\s]{1})%{GREEDYDATA:log_message}"
                ]
            }
        }
        mutate {
            gsub => ["event_service", ": ", ""]
            remove_field => ["ex_log_level_word", "empty_space1", "unparsed_log_message"]
        }
        translate {
            field => "log_level_char"
            destination => "log_level"
            dictionary => [
                "A", "AUDIT",
                "D", "DEBUG",
                "I", "INFO",
                "W", "WARN",
                "E", "ERROR",
                "F", "FATAL",
                "O", "INFO",
                "R", "WARN"
            ]
            exact => true
            remove_field => ["log_level_char"]
        }
        date {
            # ex: 5/30/17 2:43:59:281 EDT
            match => ["log_date","M/dd/YY H:mm:ss:SSS"]
            timezone => "America/New_York"
            remove_field => ["log_date"]
        }
    }

    if [type] == "cognos_pogo_log" {
        grok {
            match => [
                "message",
                "\A%{TIMESTAMP_ISO8601:log_date}%{SPACE}%{LOGLEVEL:log_level}%{SPACE}\[(?<namespace>((\.){0,1}[a-zA-Z0-9\-])+((\.){1}[a-zA-Z0-9\-]+){1})\]%{SPACE}(?<thread>.*??\:)%{SPACE}%{GREEDYDATA:log_message}"
            ]
        }
        mutate {
            gsub => ["thread", ":", ""]
        }
        date {
            # ex: 2017-05-29 14:58:26.632
            match => ["log_date","YYYY-MM-dd HH:mm:ss.SSS"]
            timezone => "America/New_York"
            remove_field => ["log_date"]
        }
    }

    if [type] == "sharepoint_uls" {
        #ignore log comments
        if [message] =~ "^#" {
            drop {}
        }
        mutate {
            strip => ["message"]
        }
        grok {
            patterns_dir => ["./patterns"]
            match => [
                "message",
                "(%{DATESTAMP:sptimestamp}\*?*%{SPACE}%{PROG:sp_process}%{SPACE}\(%{BASE16NUM:sp_pid}\)%{SPACE}%{BASE16NUM:sp_tid}%{SPACE}\t+%{DATA:sp_area}%{SPACE}\t+%{DATA:sp_category}%{SPACE}\t+%{DATA:sp_eventid}\t+%{SPACE}%{WORD:severity}%{SPACE}%{GREEDYDATA:sp_eventmessage})"
            ]
            tag_on_failure => ["not.spuls"]
        }
        mutate {
            # Avoid failed to parse issue.
            gsub =>["sptimestamp","/","-"]
            gsub =>["sptimestamp","\*",""]
        }
        date {
            match => ["sptimestamp","MM-dd-YYYY HH:mm:ss.SS"]
            timezone => "America/New_York"
            remove_field => ["sptimestamp"]
        }
        mutate {
            #Clean up the space char issue.
            gsub =>["sp_tid","-","_"]
            gsub =>["sp_area"," ",""]
            gsub =>["sp_category"," ",""]
            uppercase => ["severity"]
            lowercase => ["type"]
        }
    }
}

output {
    elasticsearch {
        hosts => "elasticsearch:9200"
        index => "%{[@metadata][beat]}-%{[@metadata][type]}-%{+YYYY.MM.dd}"
        document_type => "%{[@metadata][type]}"
    }
}
